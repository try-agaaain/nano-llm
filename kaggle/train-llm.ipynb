{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27fde7e0",
   "metadata": {},
   "source": [
    "# NanoLLM Training on Kaggle\n",
    "\n",
    "这个 notebook 从 GitHub 仓库拉取 nano-llm 最新代码，并使用 TinyStories Narrative Classification 数据集进行训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181cc189",
   "metadata": {},
   "source": [
    "## 1. 设置环境变量\n",
    "\n",
    "从 Kaggle 的环境中获取 HuggingFace 和 Weights & Biases 的 API 密钥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d252dadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "# 获取环境变量\n",
    "user_secrets = UserSecretsClient()\n",
    "try:\n",
    "    secret_value_0 = user_secrets.get_secret(\"HF_TOKEN\")\n",
    "    os.environ[\"HF_TOKEN\"] = secret_value_0\n",
    "    print(\"✅ HF_TOKEN 已设置\")\n",
    "except:\n",
    "    print(\"⚠️  HF_TOKEN 未找到\")\n",
    "\n",
    "try:\n",
    "    secret_value_1 = user_secrets.get_secret(\"WANDB_API_KEY\")\n",
    "    os.environ[\"WANDB_API_KEY\"] = secret_value_1\n",
    "    print(\"✅ WANDB_API_KEY 已设置\")\n",
    "except:\n",
    "    print(\"⚠️  WANDB_API_KEY 未找到\")\n",
    "\n",
    "print(f\"\\n环境变量配置完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f94f31",
   "metadata": {},
   "source": [
    "## 2. 安装依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d0ce12",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install -q datasets>=2.10.0 transformers>=4.30.0 tokenizers>=0.13.0 hf-transfer>=0.1.9 huggingface-hub>=0.36.1 kaggle>=1.7.4.5 wandb>=0.24.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cb4948",
   "metadata": {},
   "source": [
    "## 3. 从 GitHub 克隆 nano-llm 仓库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb86413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# 克隆仓库\n",
    "repo_url = \"https://github.com/try-agaaain/nano-llm.git\"\n",
    "repo_dir = \"/kaggle/working/nano-llm\"\n",
    "\n",
    "if not os.path.exists(repo_dir):\n",
    "    print(f\"正在从 GitHub 克隆仓库: {repo_url}\")\n",
    "    os.system(f\"git clone {repo_url} {repo_dir}\")\n",
    "    print(f\"✅ 仓库已克隆到: {repo_dir}\")\n",
    "else:\n",
    "    print(f\"仓库已存在于: {repo_dir}\")\n",
    "\n",
    "# 显示仓库内容\n",
    "print(\"\\n仓库结构:\")\n",
    "for root, dirs, files in os.walk(repo_dir):\n",
    "    level = root.replace(repo_dir, '').count(os.sep)\n",
    "    indent = ' ' * 2 * level\n",
    "    print(f'{indent}{os.path.basename(root)}/')\n",
    "    subindent = ' ' * 2 * (level + 1)\n",
    "    for file in files[:5]:  # 只显示前5个文件\n",
    "        print(f'{subindent}{file}')\n",
    "    if len(files) > 5:\n",
    "        print(f'{subindent}... ({len(files) - 5} 更多文件)')\n",
    "    if level >= 2:  # 限制深度\n",
    "        dirs.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ebedef",
   "metadata": {},
   "source": [
    "## 4. 检查数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf9f63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Kaggle 数据集路径\n",
    "train_csv = \"/kaggle/input/tinystories-narrative-classification/train.csv\"\n",
    "val_csv = \"/kaggle/input/tinystories-narrative-classification/validation.csv\"\n",
    "\n",
    "# 检查文件\n",
    "print(\"数据集文件检查:\")\n",
    "print(f\"  Train CSV: {'✅ 存在' if os.path.exists(train_csv) else '❌ 不存在'} - {os.path.getsize(train_csv) / 1024 / 1024:.2f} MB\" if os.path.exists(train_csv) else f\"  Train CSV: ❌ 不存在\")\n",
    "print(f\"  Val CSV: {'✅ 存在' if os.path.exists(val_csv) else '❌ 不存在'} - {os.path.getsize(val_csv) / 1024 / 1024:.2f} MB\" if os.path.exists(val_csv) else f\"  Val CSV: ❌ 不存在\")\n",
    "\n",
    "# 显示数据样本\n",
    "if os.path.exists(train_csv):\n",
    "    print(\"\\n训练数据集样本:\")\n",
    "    df_train = pd.read_csv(train_csv)\n",
    "    print(f\"  行数: {len(df_train)}\")\n",
    "    print(f\"  列: {df_train.columns.tolist()}\")\n",
    "    print(f\"\\n前3行预览:\")\n",
    "    print(df_train.head(3))\n",
    "\n",
    "if os.path.exists(val_csv):\n",
    "    print(\"\\n验证数据集样本:\")\n",
    "    df_val = pd.read_csv(val_csv)\n",
    "    print(f\"  行数: {len(df_val)}\")\n",
    "    print(f\"  列: {df_val.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4311631",
   "metadata": {},
   "source": [
    "## 5. 运行训练脚本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a27deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 切换到 nano-llm 目录\n",
    "repo_dir = \"/kaggle/working/nano-llm\"\n",
    "os.chdir(repo_dir)\n",
    "\n",
    "# 添加到 Python 路径\n",
    "sys.path.insert(0, repo_dir)\n",
    "\n",
    "print(f\"当前工作目录: {os.getcwd()}\")\n",
    "print(f\"Python 路径已更新\")\n",
    "\n",
    "# 确保环境变量已设置\n",
    "print(f\"\\n环境变量检查:\")\n",
    "print(f\"  HF_TOKEN: {'✅ 已设置' if os.getenv('HF_TOKEN') else '❌ 未设置'}\")\n",
    "print(f\"  WANDB_API_KEY: {'✅ 已设置' if os.getenv('WANDB_API_KEY') else '❌ 未设置'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64081659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# 确保在正确的目录\n",
    "repo_dir = \"/kaggle/working/nano-llm\"\n",
    "os.chdir(repo_dir)\n",
    "\n",
    "print(\"启动训练脚本...\\n\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 运行 train.py\n",
    "result = subprocess.run(\n",
    "    [sys.executable, \"train.py\"],\n",
    "    cwd=repo_dir,\n",
    "    env={**os.environ},\n",
    "    capture_output=False,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\n训练脚本执行完成，退出码: {result.returncode}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38da5362",
   "metadata": {},
   "source": [
    "## 6. 检查输出结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3898f89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "repo_dir = \"/kaggle/working/nano-llm\"\n",
    "\n",
    "# 检查模型文件\n",
    "print(\"模型输出文件:\")\n",
    "model_files = glob.glob(os.path.join(repo_dir, \"*.pt\"))\n",
    "for file in model_files:\n",
    "    size = os.path.getsize(file) / 1024 / 1024\n",
    "    print(f\"  {os.path.basename(file)}: {size:.2f} MB\")\n",
    "\n",
    "# 检查 tokenizer\n",
    "print(\"\\nTokenizer 文件:\")\n",
    "tokenizer_dir = os.path.join(repo_dir, \"tokenizer\")\n",
    "if os.path.exists(tokenizer_dir):\n",
    "    for file in os.listdir(tokenizer_dir):\n",
    "        file_path = os.path.join(tokenizer_dir, file)\n",
    "        if os.path.isfile(file_path):\n",
    "            size = os.path.getsize(file_path) / 1024\n",
    "            print(f\"  {file}: {size:.2f} KB\")\n",
    "\n",
    "print(\"\\n✅ 训练完成！模型和 tokenizer 已保存。\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
