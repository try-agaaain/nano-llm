{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NanoLLM Training on Kaggle\n",
    "\n",
    "Clone nano-llm from GitHub and train using TinyStories dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "def get_secret(label, config_path='/kaggle/input/my-secrets/config.yaml'):\n",
    "    \"\"\"Get secret from Kaggle secrets or config.yaml in private dataset.\"\"\"\n",
    "    try:\n",
    "        from kaggle_secrets import UserSecretsClient\n",
    "        secret = UserSecretsClient().get_secret(label)\n",
    "        if secret:\n",
    "            return secret\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    if os.path.exists(config_path):\n",
    "        with open(config_path) as f:\n",
    "            config = yaml.safe_load(f)\n",
    "            return config.get(label)\n",
    "\n",
    "    raise ValueError(f\"Secret '{label}' not found in {config_path}\")\n",
    "\n",
    "# Set environment variables with fallback\n",
    "os.environ['HF_TOKEN'] = get_secret('HF_TOKEN')\n",
    "print('[OK] HF_TOKEN set')\n",
    "\n",
    "os.environ['WANDB_API_KEY'] = get_secret('WANDB_API_KEY')\n",
    "print('[OK] WANDB_API_KEY set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install --upgrade --force-reinstall -q datasets>=2.10.0 transformers>=4.30.0 tokenizers>=0.13.0 hf-transfer>=0.1.9 huggingface-hub>=0.36.1 kaggle>=1.7.4.5 wandb>=0.24.2 pyyaml>=6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "repo_url = 'https://github.com/try-agaaain/nano-llm.git'\n",
    "repo_dir = '/kaggle/working/nano-llm'\n",
    "if not os.path.exists(repo_dir):\n",
    "    os.system(f'git clone {repo_url} {repo_dir}')\n",
    "print(f'Repository at: {repo_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "print(wandb.__version__)\n",
    "print(wandb.__file__)\n",
    "\n",
    "!python /kaggle/working/nano-llm/train.py\n",
    "!python /kaggle/working/nano-llm/inference.py\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
